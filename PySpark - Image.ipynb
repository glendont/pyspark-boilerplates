{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"import os\\nfrom pyspark import SparkContext\\nfrom pyspark.conf import SparkConf\\nfrom pyspark.context import SparkContext\\nfrom pyspark import SparkFiles\\n\\nimport pyspark.sql.functions as F  ## similar to numpy for pandas\\nfrom pyspark.sql import types as T\\n\\n%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"import os\\nfrom pyspark import SparkContext\\nfrom pyspark.conf import SparkConf\\nfrom pyspark.context import SparkContext\\nfrom pyspark import SparkFiles\\n\\nimport pyspark.sql.functions as F  ## similar to numpy for pandas\\nfrom pyspark.sql import types as T\\n\\n%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from pyspark import SparkContext\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark import SparkFiles\n",
    "\n",
    "import pyspark.sql.functions as F  ## similar to numpy for pandas\n",
    "from pyspark.sql import types as T\n",
    "\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"sc = SparkContext(\\\"local\\\", \\\"MyApplication\\\")\";\n",
       "                var nbb_formatted_code = \"sc = SparkContext(\\\"local\\\", \\\"MyApplication\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sc = SparkContext(\"local\", \"MyApplication\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"sc.stop()\";\n",
       "                var nbb_formatted_code = \"sc.stop()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"from sparkdl import readImages\\nfrom pyspark.sql.functions import lit\\n\\nloc = os.path.abspath(\\\"\\\")\\ndata_loc = f\\\"{loc}/images/\\\"\\n\\nimg_dir = data_loc\\n\\n# Read images and Create training & test DataFrames for transfer learning\\njobs_df = readImages(img_dir + \\\"/jobs\\\").withColumn(\\\"label\\\", lit(1))\\nzuckerberg_df = readImages(img_dir + \\\"/zuckerberg\\\").withColumn(\\\"label\\\", lit(0))\\njobs_train, jobs_test = jobs_df.randomSplit([0.6, 0.4])\\nzuckerberg_train, zuckerberg_test = zuckerberg_df.randomSplit([0.6, 0.4])\\n\\n# dataframe for training a classification model\\ntrain_df = jobs_train.unionAll(zuckerberg_train)\\n\\n# dataframe for testing the classification model\\ntest_df = jobs_test.unionAll(zuckerberg_test)\";\n",
       "                var nbb_formatted_code = \"from sparkdl import readImages\\nfrom pyspark.sql.functions import lit\\n\\nloc = os.path.abspath(\\\"\\\")\\ndata_loc = f\\\"{loc}/images/\\\"\\n\\nimg_dir = data_loc\\n\\n# Read images and Create training & test DataFrames for transfer learning\\njobs_df = readImages(img_dir + \\\"/jobs\\\").withColumn(\\\"label\\\", lit(1))\\nzuckerberg_df = readImages(img_dir + \\\"/zuckerberg\\\").withColumn(\\\"label\\\", lit(0))\\njobs_train, jobs_test = jobs_df.randomSplit([0.6, 0.4])\\nzuckerberg_train, zuckerberg_test = zuckerberg_df.randomSplit([0.6, 0.4])\\n\\n# dataframe for training a classification model\\ntrain_df = jobs_train.unionAll(zuckerberg_train)\\n\\n# dataframe for testing the classification model\\ntest_df = jobs_test.unionAll(zuckerberg_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sparkdl import readImages\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "loc = os.path.abspath(\"\")\n",
    "data_loc = f\"{loc}/images/\"\n",
    "\n",
    "img_dir = data_loc\n",
    "\n",
    "# Read images and Create training & test DataFrames for transfer learning\n",
    "jobs_df = readImages(img_dir + \"/jobs\").withColumn(\"label\", lit(1))\n",
    "zuckerberg_df = readImages(img_dir + \"/zuckerberg\").withColumn(\"label\", lit(0))\n",
    "jobs_train, jobs_test = jobs_df.randomSplit([0.6, 0.4])\n",
    "zuckerberg_train, zuckerberg_test = zuckerberg_df.randomSplit([0.6, 0.4])\n",
    "\n",
    "# dataframe for training a classification model\n",
    "train_df = jobs_train.unionAll(zuckerberg_train)\n",
    "\n",
    "# dataframe for testing the classification model\n",
    "test_df = jobs_test.unionAll(zuckerberg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+\n",
      "|            filePath|               image|label|\n",
      "+--------------------+--------------------+-----+\n",
      "|file:/Users/glend...|[RGB, 222, 227, 3...|    1|\n",
      "|file:/Users/glend...|[RGB, 276, 183, 3...|    1|\n",
      "|file:/Users/glend...|[RGB, 185, 273, 3...|    1|\n",
      "|file:/Users/glend...|[RGB, 268, 188, 3...|    1|\n",
      "|file:/Users/glend...|[RGB, 223, 226, 3...|    1|\n",
      "|file:/Users/glend...|[RGB, 183, 275, 3...|    1|\n",
      "|file:/Users/glend...|[RGB, 177, 284, 3...|    1|\n",
      "|file:/Users/glend...|[RGB, 218, 231, 3...|    1|\n",
      "|file:/Users/glend...|[RGB, 183, 275, 3...|    1|\n",
      "|file:/Users/glend...|[RGB, 220, 229, 3...|    1|\n",
      "|file:/Users/glend...|[RGB, 245, 206, 3...|    1|\n",
      "|file:/Users/glend...|[RGB, 193, 262, 3...|    1|\n",
      "|file:/Users/glend...|[RGB, 189, 267, 3...|    1|\n",
      "|file:/Users/glend...|[RGB, 276, 182, 3...|    0|\n",
      "|file:/Users/glend...|[RGB, 179, 282, 3...|    0|\n",
      "|file:/Users/glend...|[RGB, 183, 275, 3...|    0|\n",
      "|file:/Users/glend...|[RGB, 183, 275, 3...|    0|\n",
      "|file:/Users/glend...|[RGB, 243, 207, 3...|    0|\n",
      "|file:/Users/glend...|[RGB, 275, 183, 3...|    0|\n",
      "|file:/Users/glend...|[RGB, 183, 275, 3...|    0|\n",
      "+--------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"train_df.show()\";\n",
       "                var nbb_formatted_code = \"train_df.show()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"import tensorflow as tf\";\n",
       "                var nbb_formatted_code = \"import tensorflow as tf\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: done\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/glendont/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - python=3.6\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    _anaconda_depends-5.0.1    |   py36h6e48e2d_1           6 KB\n",
      "    _ipyw_jlab_nb_ext_conf-0.1.0|           py36_0           4 KB\n",
      "    alabaster-0.7.12           |           py36_0          18 KB\n",
      "    anaconda-custom            |           py36_1           3 KB\n",
      "    anaconda-client-1.7.2      |           py36_0         147 KB\n",
      "    anaconda-navigator-1.9.12  |           py36_0         5.6 MB\n",
      "    appnope-0.1.0              |   py36hf537a9a_0           8 KB\n",
      "    appscript-1.1.0            |   py36h1de35cc_0         273 KB\n",
      "    asn1crypto-1.3.0           |           py36_0         163 KB\n",
      "    astroid-2.3.3              |           py36_0         272 KB\n",
      "    astropy-2.0.16             |   py36h1de35cc_0         5.4 MB\n",
      "    backports.os-0.1.1         |           py36_0          15 KB\n",
      "    backports.shutil_get_terminal_size-1.0.0|           py36_2           9 KB\n",
      "    beautifulsoup4-4.6.3       |           py36_0         145 KB\n",
      "    bitarray-1.2.1             |   py36h1de35cc_0          80 KB\n",
      "    bkcharts-0.2               |           py36_0         132 KB\n",
      "    blaze-0.11.3               |           py36_0         610 KB\n",
      "    bleach-3.1.4               |             py_0         114 KB\n",
      "    bokeh-2.0.1                |           py36_0         5.3 MB\n",
      "    boto-2.49.0                |           py36_0         1.2 MB\n",
      "    bottleneck-1.3.1           |   py36h1d22016_0         109 KB\n",
      "    certifi-2020.4.5.1         |           py36_0         155 KB\n",
      "    cffi-1.14.0                |   py36hb5b8e2f_0         215 KB\n",
      "    chardet-3.0.4              |        py36_1003         180 KB\n",
      "    click-7.1.1                |             py_0          71 KB\n",
      "    clyent-1.2.2               |           py36_1          19 KB\n",
      "    colorama-0.4.3             |             py_0          20 KB\n",
      "    conda-4.8.3                |           py36_0         2.8 MB\n",
      "    conda-build-3.15.1         |           py36_0         447 KB\n",
      "    conda-package-handling-1.6.0|   py36h1de35cc_0         1.3 MB\n",
      "    contextlib2-0.6.0.post1    |             py_0          16 KB\n",
      "    cryptography-2.8           |   py36ha12b0ac_0         522 KB\n",
      "    cycler-0.10.0              |   py36hfc81398_0          13 KB\n",
      "    cython-0.29.15             |   py36h0a44026_0         1.9 MB\n",
      "    cytoolz-0.10.1             |   py36h1de35cc_0         319 KB\n",
      "    datashape-0.5.4            |           py36_1         103 KB\n",
      "    decorator-4.4.2            |             py_0          14 KB\n",
      "    docutils-0.16              |           py36_0         662 KB\n",
      "    entrypoints-0.3            |           py36_0          12 KB\n",
      "    et_xmlfile-1.0.1           |   py36h1315bdc_0          21 KB\n",
      "    fastcache-1.1.0            |   py36h1de35cc_0          29 KB\n",
      "    flask-cors-3.0.8           |             py_0          17 KB\n",
      "    future-0.18.2              |           py36_0         638 KB\n",
      "    gevent-1.4.0               |   py36h1de35cc_0         1.8 MB\n",
      "    gmpy2-2.0.8                |   py36h6ef4df4_2         143 KB\n",
      "    greenlet-0.4.15            |   py36h1de35cc_0          17 KB\n",
      "    h5py-2.10.0                |   py36h3134771_0         845 KB\n",
      "    heapdict-1.0.1             |             py_0           9 KB\n",
      "    html5lib-1.0.1             |           py36_0         187 KB\n",
      "    idna-2.9                   |             py_1          49 KB\n",
      "    imageio-2.8.0              |             py_0         3.0 MB\n",
      "    imagesize-1.2.0            |             py_0          10 KB\n",
      "    importlib_metadata-1.5.0   |           py36_0          48 KB\n",
      "    ipykernel-5.1.4            |   py36h39e3cac_0         172 KB\n",
      "    ipython-6.2.1              |   py36h3dda519_1         912 KB\n",
      "    ipython_genutils-0.2.0     |           py36_0          40 KB\n",
      "    isort-4.3.21               |           py36_0          69 KB\n",
      "    itsdangerous-1.1.0         |           py36_0          28 KB\n",
      "    jedi-0.16.0                |           py36_0         756 KB\n",
      "    jinja2-2.11.1              |             py_0         104 KB\n",
      "    jsonschema-2.6.0           |   py36hb385e00_0          65 KB\n",
      "    jupyter-1.0.0              |           py36_7           6 KB\n",
      "    jupyter_console-5.2.0      |           py36_1          37 KB\n",
      "    jupyterlab-1.2.6           |     pyhf63ae98_0         2.8 MB\n",
      "    jupyterlab_launcher-0.13.1 |           py36_0          38 KB\n",
      "    kiwisolver-1.1.0           |   py36h0a44026_0          54 KB\n",
      "    lazy-object-proxy-1.4.3    |   py36h1de35cc_0          28 KB\n",
      "    llvmlite-0.31.0            |   py36h1341992_0        11.2 MB\n",
      "    locket-0.2.0               |   py36hca03003_1           8 KB\n",
      "    lxml-4.5.0                 |   py36hef8c89e_0         1.2 MB\n",
      "    markupsafe-1.1.1           |   py36h1de35cc_0          27 KB\n",
      "    matplotlib-3.1.1           |   py36h54f8f79_0         4.9 MB\n",
      "    mccabe-0.6.1               |           py36_1          14 KB\n",
      "    mistune-0.8.4              |   py36h1de35cc_0          55 KB\n",
      "    mkl-service-2.3.0          |   py36hfbe908c_0         202 KB\n",
      "    mpmath-1.1.0               |           py36_0         776 KB\n",
      "    msgpack-python-1.0.0       |   py36h04f5b5a_1          81 KB\n",
      "    multipledispatch-0.6.0     |           py36_0          21 KB\n",
      "    navigator-updater-0.2.1    |           py36_0         690 KB\n",
      "    nbformat-5.0.4             |             py_0          89 KB\n",
      "    nltk-3.4.5                 |           py36_0         1.7 MB\n",
      "    nose-1.3.7                 |           py36_2         217 KB\n",
      "    notebook-5.2.2             |   py36h124cd7f_0         3.7 MB\n",
      "    numba-0.47.0               |   py36h6440ff4_0         2.9 MB\n",
      "    numexpr-2.7.0              |   py36h27c97d8_0         118 KB\n",
      "    numpy-1.14.2               |   py36ha9ae307_0         3.1 MB\n",
      "    odo-0.5.1                  |   py36hc1af34a_0         207 KB\n",
      "    olefile-0.46               |           py36_0          48 KB\n",
      "    packaging-20.3             |             py_0          36 KB\n",
      "    pandas-0.25.3              |   py36h0a44026_0         8.0 MB\n",
      "    pandocfilters-1.4.2        |           py36_1          13 KB\n",
      "    pathlib2-2.3.5             |           py36_0          37 KB\n",
      "    patsy-0.5.1                |           py36_0         275 KB\n",
      "    pep8-1.7.1                 |           py36_0          53 KB\n",
      "    pexpect-4.8.0              |           py36_0          82 KB\n",
      "    pickleshare-0.7.5          |           py36_0          13 KB\n",
      "    pillow-6.2.1               |   py36hb68e598_0         547 KB\n",
      "    pip-20.0.2                 |           py36_1         1.7 MB\n",
      "    pkginfo-1.5.0.1            |           py36_0          44 KB\n",
      "    ply-3.11                   |           py36_0          81 KB\n",
      "    prompt_toolkit-1.0.15      |   py36haeda067_0         340 KB\n",
      "    psutil-5.7.0               |   py36h1de35cc_0         323 KB\n",
      "    ptyprocess-0.6.0           |           py36_0          23 KB\n",
      "    py-1.8.1                   |             py_0          71 KB\n",
      "    pycodestyle-2.5.0          |           py36_0          61 KB\n",
      "    pycosat-0.6.3              |   py36h1de35cc_0          81 KB\n",
      "    pycparser-2.20             |             py_0          92 KB\n",
      "    pycrypto-2.6.1             |   py36h1de35cc_9         369 KB\n",
      "    pycurl-7.43.0.3            |   py36ha12b0ac_0          65 KB\n",
      "    pyflakes-2.1.1             |           py36_0         108 KB\n",
      "    pylint-2.4.4               |           py36_0         422 KB\n",
      "    pyodbc-4.0.30              |   py36h0a44026_0          62 KB\n",
      "    pyopenssl-19.1.0           |           py36_0          87 KB\n",
      "    pyqt-5.9.2                 |   py36h655552a_2         3.6 MB\n",
      "    pysocks-1.7.1              |           py36_0          30 KB\n",
      "    pytables-3.5.1             |   py36h5bccee9_0         1.2 MB\n",
      "    pytest-3.2.5               |   py36hd0a8424_0         286 KB\n",
      "    python-dateutil-2.8.1      |             py_0         224 KB\n",
      "    python.app-2               |          py36_10         1.4 MB\n",
      "    pywavelets-1.0.3           |   py36h1d22016_1         3.4 MB\n",
      "    pyyaml-5.3.1               |   py36h1de35cc_0         162 KB\n",
      "    pyzmq-18.1.1               |   py36h0a44026_0         402 KB\n",
      "    qtawesome-0.7.0            |             py_0         726 KB\n",
      "    requests-2.23.0            |           py36_0          91 KB\n",
      "    retrying-1.3.3             |           py36_2          16 KB\n",
      "    ruamel_yaml-0.15.87        |   py36h1de35cc_0         237 KB\n",
      "    scikit-image-0.15.0        |   py36h0a44026_0        24.2 MB\n",
      "    scikit-learn-0.20.3        |   py36h27c97d8_0         4.1 MB\n",
      "    scipy-1.3.2                |   py36h1410ff5_0        12.5 MB\n",
      "    seaborn-0.10.0             |             py_0         163 KB\n",
      "    setuptools-46.1.3          |           py36_0         511 KB\n",
      "    simplegeneric-0.8.1        |           py36_2           9 KB\n",
      "    singledispatch-3.4.0.3     |   py36hf20db9d_0          16 KB\n",
      "    sip-4.19.8                 |   py36h0a44026_0         238 KB\n",
      "    six-1.14.0                 |           py36_0          26 KB\n",
      "    sortedcollections-1.1.2    |           py36_0          18 KB\n",
      "    sortedcontainers-2.1.0     |           py36_0          43 KB\n",
      "    sphinxcontrib-1.0          |           py36_1           4 KB\n",
      "    spyder-3.2.8               |           py36_0         2.1 MB\n",
      "    sqlalchemy-1.3.16          |   py36h1de35cc_0         1.4 MB\n",
      "    statsmodels-0.10.1         |   py36h1d22016_0         7.0 MB\n",
      "    sympy-1.5.1                |           py36_0         8.3 MB\n",
      "    terminado-0.8.3            |           py36_0          25 KB\n",
      "    testpath-0.4.4             |             py_0          88 KB\n",
      "    tornado-5.1.1              |   py36h1de35cc_0         626 KB\n",
      "    traitlets-4.3.3            |           py36_0         140 KB\n",
      "    typed-ast-1.4.1            |   py36h1de35cc_0         173 KB\n",
      "    typing-3.6.4               |           py36_0          44 KB\n",
      "    typing_extensions-3.7.4.1  |           py36_0          39 KB\n",
      "    unicodecsv-0.14.1          |   py36he531d66_0          25 KB\n",
      "    urllib3-1.25.8             |           py36_0         166 KB\n",
      "    wcwidth-0.1.9              |             py_0          24 KB\n",
      "    webencodings-0.5.1         |           py36_1          19 KB\n",
      "    wheel-0.34.2               |           py36_0          50 KB\n",
      "    widgetsnbextension-3.5.1   |           py36_0         867 KB\n",
      "    wrapt-1.12.1               |   py36h1de35cc_1          45 KB\n",
      "    xlrd-1.2.0                 |           py36_0         176 KB\n",
      "    xlwings-0.18.0             |           py36_0         384 KB\n",
      "    xlwt-1.2.0                 |   py36h5ad1178_0         158 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       159.6 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  blaze              pkgs/main/osx-64::blaze-0.11.3-py36_0\n",
      "  datashape          pkgs/main/osx-64::datashape-0.5.4-py36_1\n",
      "  flask-cors         pkgs/main/noarch::flask-cors-3.0.8-py_0\n",
      "  jupyterlab_launch~ pkgs/main/osx-64::jupyterlab_launcher-0.13.1-py36_0\n",
      "  odo                pkgs/main/osx-64::odo-0.5.1-py36hc1af34a_0\n",
      "  typed-ast          pkgs/main/osx-64::typed-ast-1.4.1-py36h1de35cc_0\n",
      "  typing             pkgs/main/osx-64::typing-3.6.4-py36_0\n",
      "  typing_extensions  pkgs/main/osx-64::typing_extensions-3.7.4.1-py36_0\n",
      "\n",
      "The following packages will be REMOVED:\n",
      "\n",
      "  atomicwrites-1.3.0-py37_1\n",
      "  attrs-19.1.0-py37_1\n",
      "  backcall-0.1.0-py37_0\n",
      "  joblib-0.13.2-py37_0\n",
      "  keyring-18.0.0-py37_0\n",
      "  mkl_fft-1.0.12-py37h5e564d8_0\n",
      "  mkl_random-1.0.2-py37h27c97d8_0\n",
      "  mock-3.0.5-py37_0\n",
      "  more-itertools-7.0.0-py37_0\n",
      "  numpy-base-1.16.4-py37h6575580_0\n",
      "  py-lief-0.9.0-py37h1413db1_2\n",
      "  pyrsistent-0.14.11-py37h1de35cc_0\n",
      "  pytest-arraydiff-0.3-py37h39e3cac_0\n",
      "  pytest-astropy-0.5.0-py37_0\n",
      "  pytest-doctestplus-0.3.0-py37_0\n",
      "  pytest-openfiles-0.3.2-py37_0\n",
      "  pytest-remotedata-0.3.1-py37_0\n",
      "  python-libarchive-c-2.8-py37_11\n",
      "  send2trash-1.5.0-py37_0\n",
      "  soupsieve-1.8-py37_0\n",
      "  spyder-kernels-0.5.1-py37_0\n",
      "  wurlitzer-1.0.2-py37_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  asn1crypto                                  0.24.0-py37_0 --> 1.3.0-py36_0\n",
      "  astroid                                      2.2.5-py37_0 --> 2.3.3-py36_0\n",
      "  bitarray                             0.9.3-py37h1de35cc_0 --> 1.2.1-py36h1de35cc_0\n",
      "  bleach              pkgs/main/osx-64::bleach-3.1.0-py37_0 --> pkgs/main/noarch::bleach-3.1.4-py_0\n",
      "  bokeh                                        1.2.0-py37_0 --> 2.0.1-py36_0\n",
      "  bottleneck                           1.2.1-py37h1d22016_1 --> 1.3.1-py36h1d22016_0\n",
      "  certifi                                 2019.11.28-py37_0 --> 2020.4.5.1-py36_0\n",
      "  cffi                                1.12.3-py37hb5b8e2f_0 --> 1.14.0-py36hb5b8e2f_0\n",
      "  chardet                                      3.0.4-py37_1 --> 3.0.4-py36_1003\n",
      "  click                  pkgs/main/osx-64::click-7.0-py37_0 --> pkgs/main/noarch::click-7.1.1-py_0\n",
      "  colorama           pkgs/main/osx-64::colorama-0.4.1-py37~ --> pkgs/main/noarch::colorama-0.4.3-py_0\n",
      "  conda                                        4.8.2-py37_0 --> 4.8.3-py36_0\n",
      "  conda-package-han~                          1.3.11-py37_0 --> 1.6.0-py36h1de35cc_0\n",
      "  contextlib2        pkgs/main/osx-64::contextlib2-0.5.5-p~ --> pkgs/main/noarch::contextlib2-0.6.0.post1-py_0\n",
      "  cryptography                           2.7-py37ha12b0ac_0 --> 2.8-py36ha12b0ac_0\n",
      "  cython                             0.29.12-py37h0a44026_0 --> 0.29.15-py36h0a44026_0\n",
      "  cytoolz                             0.10.0-py37h1de35cc_0 --> 0.10.1-py36h1de35cc_0\n",
      "  decorator          pkgs/main/osx-64::decorator-4.4.0-py3~ --> pkgs/main/noarch::decorator-4.4.2-py_0\n",
      "  docutils                                      0.14-py37_0 --> 0.16-py36_0\n",
      "  future                                      0.17.1-py37_0 --> 0.18.2-py36_0\n",
      "  h5py                                 2.9.0-py37h3134771_0 --> 2.10.0-py36h3134771_0\n",
      "  heapdict           pkgs/main/osx-64::heapdict-1.0.0-py37~ --> pkgs/main/noarch::heapdict-1.0.1-py_0\n",
      "  idna                    pkgs/main/osx-64::idna-2.8-py37_0 --> pkgs/main/noarch::idna-2.9-py_1\n",
      "  imageio            pkgs/main/osx-64::imageio-2.5.0-py37_0 --> pkgs/main/noarch::imageio-2.8.0-py_0\n",
      "  imagesize          pkgs/main/osx-64::imagesize-1.1.0-py3~ --> pkgs/main/noarch::imagesize-1.2.0-py_0\n",
      "  importlib_metadata                            0.17-py37_1 --> 1.5.0-py36_0\n",
      "  ipykernel                            5.1.1-py37h39e3cac_0 --> 5.1.4-py36h39e3cac_0\n",
      "  jedi                                        0.13.3-py37_0 --> 0.16.0-py36_0\n",
      "  jinja2             pkgs/main/osx-64::jinja2-2.10.1-py37_0 --> pkgs/main/noarch::jinja2-2.11.1-py_0\n",
      "  jupyterlab         pkgs/main/osx-64::jupyterlab-1.0.2-py~ --> pkgs/main/noarch::jupyterlab-1.2.6-pyhf63ae98_0\n",
      "  lazy-object-proxy                    1.4.1-py37h1de35cc_0 --> 1.4.3-py36h1de35cc_0\n",
      "  llvmlite                            0.29.0-py37h98b8051_0 --> 0.31.0-py36h1341992_0\n",
      "  lxml                                 4.3.4-py37hef8c89e_0 --> 4.5.0-py36hef8c89e_0\n",
      "  matplotlib                           3.1.0-py37h54f8f79_0 --> 3.1.1-py36h54f8f79_0\n",
      "  mkl-service                          2.0.2-py37h1de35cc_0 --> 2.3.0-py36hfbe908c_0\n",
      "  msgpack-python                       0.6.1-py37h04f5b5a_1 --> 1.0.0-py36h04f5b5a_1\n",
      "  nbformat           pkgs/main/osx-64::nbformat-4.4.0-py37~ --> pkgs/main/noarch::nbformat-5.0.4-py_0\n",
      "  nltk                                         3.4.4-py37_0 --> 3.4.5-py36_0\n",
      "  numba                               0.44.1-py37h6440ff4_0 --> 0.47.0-py36h6440ff4_0\n",
      "  numexpr                              2.6.9-py37h7413580_0 --> 2.7.0-py36h27c97d8_0\n",
      "  openssl                                 1.1.1d-h1de35cc_4 --> 1.1.1f-h1de35cc_0\n",
      "  packaging          pkgs/main/osx-64::packaging-19.0-py37~ --> pkgs/main/noarch::packaging-20.3-py_0\n",
      "  pandas                              0.24.2-py37h0a44026_0 --> 0.25.3-py36h0a44026_0\n",
      "  pathlib2                                     2.3.4-py37_0 --> 2.3.5-py36_0\n",
      "  pexpect                                      4.7.0-py37_0 --> 4.8.0-py36_0\n",
      "  pillow                               6.1.0-py37hb68e598_0 --> 6.2.1-py36hb68e598_0\n",
      "  pip                                         19.1.1-py37_0 --> 20.0.2-py36_1\n",
      "  psutil                               5.6.3-py37h1de35cc_0 --> 5.7.0-py36h1de35cc_0\n",
      "  py                      pkgs/main/osx-64::py-1.8.0-py37_0 --> pkgs/main/noarch::py-1.8.1-py_0\n",
      "  pycparser          pkgs/main/osx-64::pycparser-2.19-py37~ --> pkgs/main/noarch::pycparser-2.20-py_0\n",
      "  pylint                                       2.3.1-py37_0 --> 2.4.4-py36_0\n",
      "  pyodbc                              4.0.26-py37h0a44026_0 --> 4.0.30-py36h0a44026_0\n",
      "  pyopenssl                                   19.0.0-py37_0 --> 19.1.0-py36_0\n",
      "  pysocks                                      1.7.0-py37_0 --> 1.7.1-py36_0\n",
      "  python-dateutil    pkgs/main/osx-64::python-dateutil-2.8~ --> pkgs/main/noarch::python-dateutil-2.8.1-py_0\n",
      "  python.app                                       2-py37_9 --> 2-py36_10\n",
      "  pyyaml                               5.1.1-py37h1de35cc_0 --> 5.3.1-py36h1de35cc_0\n",
      "  pyzmq                               18.0.0-py37h0a44026_0 --> 18.1.1-py36h0a44026_0\n",
      "  qtawesome          pkgs/main/osx-64::qtawesome-0.5.7-py3~ --> pkgs/main/noarch::qtawesome-0.7.0-py_0\n",
      "  requests                                    2.22.0-py37_0 --> 2.23.0-py36_0\n",
      "  ruamel_yaml                        0.15.46-py37h1de35cc_0 --> 0.15.87-py36h1de35cc_0\n",
      "  scipy                                1.3.0-py37h1410ff5_0 --> 1.3.2-py36h1410ff5_0\n",
      "  seaborn            pkgs/main/osx-64::seaborn-0.9.0-py37_0 --> pkgs/main/noarch::seaborn-0.10.0-py_0\n",
      "  setuptools                                  41.0.1-py37_0 --> 46.1.3-py36_0\n",
      "  six                                         1.12.0-py37_0 --> 1.14.0-py36_0\n",
      "  sqlalchemy                           1.3.5-py37h1de35cc_0 --> 1.3.16-py36h1de35cc_0\n",
      "  statsmodels                         0.10.0-py37h1d22016_0 --> 0.10.1-py36h1d22016_0\n",
      "  sympy                                          1.4-py37_0 --> 1.5.1-py36_0\n",
      "  terminado                                    0.8.2-py37_0 --> 0.8.3-py36_0\n",
      "  testpath           pkgs/main/osx-64::testpath-0.4.2-py37~ --> pkgs/main/noarch::testpath-0.4.4-py_0\n",
      "  traitlets                                    4.3.2-py37_0 --> 4.3.3-py36_0\n",
      "  urllib3                                     1.24.2-py37_0 --> 1.25.8-py36_0\n",
      "  wcwidth            pkgs/main/osx-64::wcwidth-0.1.7-py37_0 --> pkgs/main/noarch::wcwidth-0.1.9-py_0\n",
      "  wheel                                       0.33.4-py37_0 --> 0.34.2-py36_0\n",
      "  widgetsnbextension                           3.5.0-py37_0 --> 3.5.1-py36_0\n",
      "  wrapt                               1.11.2-py37h1de35cc_0 --> 1.12.1-py36h1de35cc_1\n",
      "  xlwings                                     0.15.8-py37_0 --> 0.18.0-py36_0\n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "  _anaconda_depends                          2019.03-py37_0 --> 5.0.1-py36h6e48e2d_1\n",
      "  _ipyw_jlab_nb_ext~                           0.1.0-py37_0 --> 0.1.0-py36_0\n",
      "  alabaster                                   0.7.12-py37_0 --> 0.7.12-py36_0\n",
      "  anaconda                                    custom-py37_1 --> custom-py36_1\n",
      "  anaconda-client                              1.7.2-py37_0 --> 1.7.2-py36_0\n",
      "  anaconda-navigator                          1.9.12-py37_0 --> 1.9.12-py36_0\n",
      "  appnope                                      0.1.0-py37_0 --> 0.1.0-py36hf537a9a_0\n",
      "  appscript                            1.1.0-py37h1de35cc_0 --> 1.1.0-py36h1de35cc_0\n",
      "  astropy                              3.2.1-py37h1de35cc_0 --> 2.0.16-py36h1de35cc_0\n",
      "  backports.os                                 0.1.1-py37_0 --> 0.1.1-py36_0\n",
      "  backports.shutil_~                           1.0.0-py37_2 --> 1.0.0-py36_2\n",
      "  beautifulsoup4                               4.7.1-py37_1 --> 4.6.3-py36_0\n",
      "  bkcharts                                       0.2-py37_0 --> 0.2-py36_0\n",
      "  boto                                        2.49.0-py37_0 --> 2.49.0-py36_0\n",
      "  clyent                                       1.2.2-py37_1 --> 1.2.2-py36_1\n",
      "  conda-build                                 3.18.8-py37_0 --> 3.15.1-py36_0\n",
      "  cycler                                      0.10.0-py37_0 --> 0.10.0-py36hfc81398_0\n",
      "  entrypoints                                    0.3-py37_0 --> 0.3-py36_0\n",
      "  et_xmlfile                                   1.0.1-py37_0 --> 1.0.1-py36h1315bdc_0\n",
      "  fastcache                            1.1.0-py37h1de35cc_0 --> 1.1.0-py36h1de35cc_0\n",
      "  gevent                               1.4.0-py37h1de35cc_0 --> 1.4.0-py36h1de35cc_0\n",
      "  gmpy2                                2.0.8-py37h6ef4df4_2 --> 2.0.8-py36h6ef4df4_2\n",
      "  greenlet                            0.4.15-py37h1de35cc_0 --> 0.4.15-py36h1de35cc_0\n",
      "  html5lib                                     1.0.1-py37_0 --> 1.0.1-py36_0\n",
      "  ipython                              7.6.1-py37h39e3cac_0 --> 6.2.1-py36h3dda519_1\n",
      "  ipython_genutils                             0.2.0-py37_0 --> 0.2.0-py36_0\n",
      "  isort                                       4.3.21-py37_0 --> 4.3.21-py36_0\n",
      "  itsdangerous                                 1.1.0-py37_0 --> 1.1.0-py36_0\n",
      "  jsonschema                                   3.0.1-py37_0 --> 2.6.0-py36hb385e00_0\n",
      "  jupyter                                      1.0.0-py37_7 --> 1.0.0-py36_7\n",
      "  jupyter_console                              6.0.0-py37_0 --> 5.2.0-py36_1\n",
      "  kiwisolver                           1.1.0-py37h0a44026_0 --> 1.1.0-py36h0a44026_0\n",
      "  locket                                       0.2.0-py37_1 --> 0.2.0-py36hca03003_1\n",
      "  markupsafe                           1.1.1-py37h1de35cc_0 --> 1.1.1-py36h1de35cc_0\n",
      "  mccabe                                       0.6.1-py37_1 --> 0.6.1-py36_1\n",
      "  mistune                              0.8.4-py37h1de35cc_0 --> 0.8.4-py36h1de35cc_0\n",
      "  mpmath                                       1.1.0-py37_0 --> 1.1.0-py36_0\n",
      "  multipledispatch                             0.6.0-py37_0 --> 0.6.0-py36_0\n",
      "  navigator-updater                            0.2.1-py37_0 --> 0.2.1-py36_0\n",
      "  nose                                         1.3.7-py37_2 --> 1.3.7-py36_2\n",
      "  notebook                                     6.0.0-py37_0 --> 5.2.2-py36h124cd7f_0\n",
      "  numpy                               1.16.4-py37hacdab7b_0 --> 1.14.2-py36ha9ae307_0\n",
      "  olefile                                       0.46-py37_0 --> 0.46-py36_0\n",
      "  pandocfilters                                1.4.2-py37_1 --> 1.4.2-py36_1\n",
      "  patsy                                        0.5.1-py37_0 --> 0.5.1-py36_0\n",
      "  pep8                                         1.7.1-py37_0 --> 1.7.1-py36_0\n",
      "  pickleshare                                  0.7.5-py37_0 --> 0.7.5-py36_0\n",
      "  pkginfo                                    1.5.0.1-py37_0 --> 1.5.0.1-py36_0\n",
      "  ply                                           3.11-py37_0 --> 3.11-py36_0\n",
      "  prompt_toolkit                               2.0.9-py37_0 --> 1.0.15-py36haeda067_0\n",
      "  ptyprocess                                   0.6.0-py37_0 --> 0.6.0-py36_0\n",
      "  pycodestyle                                  2.5.0-py37_0 --> 2.5.0-py36_0\n",
      "  pycosat                              0.6.3-py37h1de35cc_0 --> 0.6.3-py36h1de35cc_0\n",
      "  pycrypto                             2.6.1-py37h1de35cc_9 --> 2.6.1-py36h1de35cc_9\n",
      "  pycurl                            7.43.0.3-py37ha12b0ac_0 --> 7.43.0.3-py36ha12b0ac_0\n",
      "  pyflakes                                     2.1.1-py37_0 --> 2.1.1-py36_0\n",
      "  pyqt                                 5.9.2-py37h655552a_2 --> 5.9.2-py36h655552a_2\n",
      "  pytables                             3.5.2-py37h5bccee9_1 --> 3.5.1-py36h5bccee9_0\n",
      "  pytest                                       5.0.1-py37_0 --> 3.2.5-py36hd0a8424_0\n",
      "  python                                   3.7.3-h359304d_0 --> 3.6.9-h359304d_0\n",
      "  pywavelets                           1.0.3-py37h1d22016_1 --> 1.0.3-py36h1d22016_1\n",
      "  retrying                                     1.3.3-py37_2 --> 1.3.3-py36_2\n",
      "  scikit-image                        0.15.0-py37h0a44026_0 --> 0.15.0-py36h0a44026_0\n",
      "  scikit-learn                        0.21.2-py37h27c97d8_0 --> 0.20.3-py36h27c97d8_0\n",
      "  simplegeneric                                0.8.1-py37_2 --> 0.8.1-py36_2\n",
      "  singledispatch                             3.4.0.3-py37_0 --> 3.4.0.3-py36hf20db9d_0\n",
      "  sip                                 4.19.8-py37h0a44026_0 --> 4.19.8-py36h0a44026_0\n",
      "  sortedcollections                            1.1.2-py37_0 --> 1.1.2-py36_0\n",
      "  sortedcontainers                             2.1.0-py37_0 --> 2.1.0-py36_0\n",
      "  sphinxcontrib                                  1.0-py37_1 --> 1.0-py36_1\n",
      "  spyder                                       3.3.6-py37_0 --> 3.2.8-py36_0\n",
      "  tornado                              6.0.3-py37h1de35cc_0 --> 5.1.1-py36h1de35cc_0\n",
      "  unicodecsv                                  0.14.1-py37_0 --> 0.14.1-py36he531d66_0\n",
      "  webencodings                                 0.5.1-py37_1 --> 0.5.1-py36_1\n",
      "  xlrd                                         1.2.0-py37_0 --> 1.2.0-py36_0\n",
      "  xlwt                                         1.3.0-py37_0 --> 1.2.0-py36h5ad1178_0\n",
      "\n",
      "\n",
      "Proceed ([y]/n)? "
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 63;\n",
       "                var nbb_unformatted_code = \"!conda install python=3.6\";\n",
       "                var nbb_formatted_code = \"!conda install python=3.6\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!conda install python=3.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==1.1 (from versions: 1.13.0rc1, 1.13.0rc2, 1.13.1, 1.13.2, 1.14.0rc0, 1.14.0rc1, 1.14.0, 1.15.0rc0, 1.15.0rc1, 1.15.0rc2, 1.15.0rc3, 1.15.0, 1.15.2, 2.0.0a0, 2.0.0b0, 2.0.0b1, 2.0.0rc0, 2.0.0rc1, 2.0.0rc2, 2.0.0, 2.0.1, 2.1.0rc0, 2.1.0rc1, 2.1.0rc2, 2.1.0, 2.2.0rc0, 2.2.0rc1, 2.2.0rc2, 2.2.0rc3)\u001b[0m\r\n",
      "\u001b[31mERROR: No matching distribution found for tensorflow==1.1\u001b[0m\r\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 59;\n",
       "                var nbb_unformatted_code = \"!pip install tensorflow==1.1\";\n",
       "                var nbb_formatted_code = \"!pip install tensorflow==1.1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install tensorflow==1.1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"from pyspark.ml.classification import LogisticRegression\\nfrom pyspark.ml import Pipeline\\nfrom sparkdl import DeepImageFeaturizer\";\n",
       "                var nbb_formatted_code = \"from pyspark.ml.classification import LogisticRegression\\nfrom pyspark.ml import Pipeline\\nfrom sparkdl import DeepImageFeaturizer\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from sparkdl import DeepImageFeaturizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"featurizer = DeepImageFeaturizer(\\n    inputCol=\\\"image\\\", outputCol=\\\"features\\\", modelName=\\\"InceptionV3\\\"\\n)\";\n",
       "                var nbb_formatted_code = \"featurizer = DeepImageFeaturizer(\\n    inputCol=\\\"image\\\", outputCol=\\\"features\\\", modelName=\\\"InceptionV3\\\"\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "featurizer = DeepImageFeaturizer(\n",
    "    inputCol=\"image\", outputCol=\"features\", modelName=\"InceptionV3\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"lr = LogisticRegression(\\n    maxIter=20, regParam=0.05, elasticNetParam=0.3, labelCol=\\\"label\\\"\\n)\";\n",
       "                var nbb_formatted_code = \"lr = LogisticRegression(\\n    maxIter=20, regParam=0.05, elasticNetParam=0.3, labelCol=\\\"label\\\"\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = LogisticRegression(\n",
    "    maxIter=20, regParam=0.05, elasticNetParam=0.3, labelCol=\"label\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'Session'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-f853cc654ea4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeaturizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/spark-1.6.0-bin-hadoop2.6/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m~/spark-1.6.0-bin-hadoop2.6/python/pyspark/ml/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                     \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# must be an Estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-1.6.0-bin-hadoop2.6/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sparkdl/transformers/named_image.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    156\u001b[0m                                              \u001b[0moutputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOutputCol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                                              modelName=self.getModelName(), featurize=True)\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-1.6.0-bin-hadoop2.6/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sparkdl/transformers/named_image.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0mmodelGraphSpec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_buildTFGraphForName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetModelName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetFeaturize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0minputCol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetInputCol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mresizedCol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"__sdl_imagesResized\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sparkdl/transformers/named_image.py\u001b[0m in \u001b[0;36m_buildTFGraphForName\u001b[0;34m(name, featurize)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0mCurrently\u001b[0m \u001b[0monly\u001b[0m \u001b[0msupports\u001b[0m \u001b[0mpre\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtrained\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mKeras\u001b[0m \u001b[0mapplications\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \"\"\"\n\u001b[0;32m--> 229\u001b[0;31m     \u001b[0mmodelData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras_apps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetKerasApplicationModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetModelData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeaturize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m     \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"session\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0moutputTensorName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"outputTensorName\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sparkdl/transformers/keras_applications.py\u001b[0m in \u001b[0;36mgetModelData\u001b[0;34m(self, featurize)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetModelData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeaturize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'Session'"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 58;\n",
       "                var nbb_unformatted_code = \"strain = Pipeline(stages=[featurizer, lr])\\nstrain.fit(train_df)\";\n",
       "                var nbb_formatted_code = \"strain = Pipeline(stages=[featurizer, lr])\\nstrain.fit(train_df)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "strain = Pipeline(stages=[featurizer, lr])\n",
    "strain.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 55;\n",
       "                var nbb_unformatted_code = \"tf.compat.v1.Session()\\ntf.compat.v1.disable_eager_execution()\\n#p_model = p.fit(train_df)\\n# transformeddf = p_model.transform(df)\";\n",
       "                var nbb_formatted_code = \"tf.compat.v1.Session()\\ntf.compat.v1.disable_eager_execution()\\n# p_model = p.fit(train_df)\\n# transformeddf = p_model.transform(df)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.compat.v1.Session()\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "# p_model = p.fit(train_df)\n",
    "# transformeddf = p_model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tf-nightly-2.0-preview (from versions: none)\u001b[0m\r\n",
      "\u001b[31mERROR: No matching distribution found for tf-nightly-2.0-preview\u001b[0m\r\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"!pip install tf-nightly-2.0-preview\";\n",
       "                var nbb_formatted_code = \"!pip install tf-nightly-2.0-preview\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install tf-nightly-2.0-preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 533440\r\n",
      "drwxr-xr-x@ 15 glendont  staff        480 Apr 20 21:59 \u001b[34m.\u001b[m\u001b[m\r\n",
      "drwxr-xr-x@ 13 glendont  staff        416 Apr 20 21:59 \u001b[34m..\u001b[m\u001b[m\r\n",
      "-rw-r--r--@  1 glendont  staff      10244 Apr 20 21:59 .DS_Store\r\n",
      "drwxr-xr-x@  6 glendont  staff        192 Apr 20 21:56 \u001b[34m.ipynb_checkpoints\u001b[m\u001b[m\r\n",
      "-rw-rw-r--@  1 glendont  staff      66193 Jun  7  2018 Ecommerce_Customers.csv\r\n",
      "-rw-r--r--   1 glendont  staff      39288 Apr 17 19:29 Natural Language Processing Tutorial.ipynb\r\n",
      "-rw-r--r--   1 glendont  staff     171049 Apr 20 23:32 PySpark Fundamentals.ipynb\r\n",
      "-rw-r--r--   1 glendont  staff      11959 Apr 20 21:53 PySpark Linear Regression.ipynb\r\n",
      "-rw-r--r--   1 glendont  staff      53034 Apr 20 23:39 PySparkImage.ipynb\r\n",
      "drwxr-xr-x@  4 glendont  staff        128 Apr 18 17:47 \u001b[34mdata\u001b[m\u001b[m\r\n",
      "-rw-r--r--@  1 glendont  staff     110650 Apr 16 23:51 finaloutput.csv\r\n",
      "-rw-r--r--   1 glendont  staff  228813984 Apr 20 22:12 flower_photos.tgz\r\n",
      "drwxr-xr-x@  5 glendont  staff        160 Apr 20 21:59 \u001b[34mimages\u001b[m\u001b[m\r\n",
      "-rw-r--r--@  1 glendont  staff   35770287 Apr 19 18:45 sf_airbnb listings.csv\r\n",
      "-rw-r--r--   1 glendont  staff       2990 Apr 17 23:43 text.txt\r\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"!ls -al\";\n",
       "                var nbb_formatted_code = \"!ls -al\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!ls -al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: tf_upgrade-v2: command not found\r\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"!tf_upgrade-v2 --infile PySparkImage.ipynb --outfile new.py\";\n",
       "                var nbb_formatted_code = \"!tf_upgrade-v2 --infile PySparkImage.ipynb --outfile new.py\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!tf_upgrade-v2 --infile PySparkImage.ipynb --outfile new.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"print(tensorflow.__version__)\";\n",
       "                var nbb_formatted_code = \"print(tensorflow.__version__)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: tensorflow 2.1.0\n",
      "Uninstalling tensorflow-2.1.0:\n",
      "  Would remove:\n",
      "    /Users/glendont/anaconda3/bin/estimator_ckpt_converter\n",
      "    /Users/glendont/anaconda3/bin/saved_model_cli\n",
      "    /Users/glendont/anaconda3/bin/tensorboard\n",
      "    /Users/glendont/anaconda3/bin/tf_upgrade_v2\n",
      "    /Users/glendont/anaconda3/bin/tflite_convert\n",
      "    /Users/glendont/anaconda3/bin/toco\n",
      "    /Users/glendont/anaconda3/bin/toco_from_protos\n",
      "    /Users/glendont/anaconda3/lib/python3.7/site-packages/tensorflow-2.1.0.dist-info/*\n",
      "    /Users/glendont/anaconda3/lib/python3.7/site-packages/tensorflow/*\n",
      "    /Users/glendont/anaconda3/lib/python3.7/site-packages/tensorflow_core/*\n",
      "Proceed (y/n)? "
     ]
    }
   ],
   "source": [
    "!pip uninstall tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
